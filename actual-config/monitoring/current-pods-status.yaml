apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:25:45Z"
    generateName: local-path-provisioner-84db5d44d9-
    labels:
      app: local-path-provisioner
      pod-template-hash: 84db5d44d9
    name: local-path-provisioner-84db5d44d9-lsp88
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: local-path-provisioner-84db5d44d9
      uid: 4c124909-c6a3-4758-9cc3-bb6d32b3f858
    resourceVersion: "481"
    uid: 441c2751-6737-4c28-a23e-dcf826ed47de
  spec:
    containers:
    - command:
      - local-path-provisioner
      - start
      - --config
      - /etc/config/config.json
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/local-path-provisioner:v0.0.24
      imagePullPolicy: IfNotPresent
      name: local-path-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config/
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6d5jc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: local-path-provisioner-service-account
    serviceAccountName: local-path-provisioner-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: local-path-config
      name: config-volume
    - name: kube-api-access-6d5jc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://633c6cbfcba0f0cc567618883cdf883cb81de454dabf843117210a367e03221a
      image: docker.io/rancher/local-path-provisioner:v0.0.24
      imageID: docker.io/rancher/local-path-provisioner@sha256:5bb33992a4ec3034c28b5e0b3c4c2ac35d3613b25b79455eb4b1a95adc82cdc0
      lastState: {}
      name: local-path-provisioner
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:25:50Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.5
    podIPs:
    - ip: 10.42.0.5
    qosClass: BestEffort
    startTime: "2025-08-13T16:25:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:25:45Z"
    generateName: coredns-6799fbcd5-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 6799fbcd5
    name: coredns-6799fbcd5-stfxd
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-6799fbcd5
      uid: 6cb5d413-ed8e-4688-9022-99dccffa6478
    resourceVersion: "483"
    uid: 8cb2010c-f33e-4295-8400-c3b11c1dbd6c
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: rancher/mirrored-coredns-coredns:1.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /etc/coredns/custom
        name: custom-config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jhhxz
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    topologySpreadConstraints:
    - labelSelector:
        matchLabels:
          k8s-app: kube-dns
      maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        - key: NodeHosts
          path: NodeHosts
        name: coredns
      name: config-volume
    - configMap:
        defaultMode: 420
        name: coredns-custom
        optional: true
      name: custom-config-volume
    - name: kube-api-access-jhhxz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7964d74d82bb28fd2fe4fa00de81937a014a41eef40174a561f128a6c9dd65f8
      image: docker.io/rancher/mirrored-coredns-coredns:1.10.1
      imageID: docker.io/rancher/mirrored-coredns-coredns@sha256:a11fafae1f8037cbbd66c5afa40ba2423936b72b4fd50a7034a7e8b955163594
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:25:50Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.2
    podIPs:
    - ip: 10.42.0.2
    qosClass: Burstable
    startTime: "2025-08-13T16:25:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
    creationTimestamp: "2025-08-13T16:25:45Z"
    generateName: helm-install-traefik-crd-
    labels:
      batch.kubernetes.io/controller-uid: 113effa0-cad5-4f50-b22e-a02eb43aa6ca
      batch.kubernetes.io/job-name: helm-install-traefik-crd
      controller-uid: 113effa0-cad5-4f50-b22e-a02eb43aa6ca
      helmcharts.helm.cattle.io/chart: traefik-crd
      job-name: helm-install-traefik-crd
    name: helm-install-traefik-crd-sr8j2
    namespace: kube-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-traefik-crd
      uid: 113effa0-cad5-4f50-b22e-a02eb43aa6ca
    resourceVersion: "616"
    uid: 36ff6d73-8e26-4a8a-b8e6-5c628fe9398f
  spec:
    containers:
    - args:
      - install
      env:
      - name: NAME
        value: traefik-crd
      - name: VERSION
      - name: REPO
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: kube-system
      - name: CHART
        value: https://%{KUBERNETES_API}%/static/charts/traefik-crd-25.0.2+up25.0.0.tgz
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: kube-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.2-build20230815
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-56m56
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: helm-traefik-crd
    serviceAccountName: helm-traefik-crd
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-traefik-crd
    - configMap:
        defaultMode: 420
        name: chart-content-traefik-crd
      name: content
    - name: kube-api-access-56m56
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:53Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:53Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5ecc5b86f3350206f8bf20b4d88f5966fbaaca4b2ee47cef6d85d6e9167bcb63
      image: docker.io/rancher/klipper-helm:v0.8.2-build20230815
      imageID: docker.io/rancher/klipper-helm@sha256:b0b0c4f73f2391697edb52adffe4fc490de1c8590606024515bb906b2813554a
      lastState: {}
      name: helm
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://5ecc5b86f3350206f8bf20b4d88f5966fbaaca4b2ee47cef6d85d6e9167bcb63
          exitCode: 0
          finishedAt: "2025-08-13T16:25:53Z"
          message: |
            Installing helm_v3 chart
          reason: Completed
          startedAt: "2025-08-13T16:25:52Z"
    hostIP: 37.59.98.241
    phase: Succeeded
    podIP: 10.42.0.6
    podIPs:
    - ip: 10.42.0.6
    qosClass: BestEffort
    startTime: "2025-08-13T16:25:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:25:54Z"
    generateName: svclb-traefik-be5bbb08-
    labels:
      app: svclb-traefik-be5bbb08
      controller-revision-hash: 574f8f8d8f
      pod-template-generation: "1"
      svccontroller.k3s.cattle.io/svcname: traefik
      svccontroller.k3s.cattle.io/svcnamespace: kube-system
    name: svclb-traefik-be5bbb08-vt77t
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: svclb-traefik-be5bbb08
      uid: b9c71814-1751-490e-b418-9005c7ba0246
    resourceVersion: "629"
    uid: b0bd64d7-2fc0-42d0-a849-37c942f01298
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - vps-6227e9e1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: SRC_PORT
        value: "80"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "80"
      - name: DEST_IPS
        value: 10.43.51.248
      image: rancher/klipper-lb:v0.4.4
      imagePullPolicy: IfNotPresent
      name: lb-tcp-80
      ports:
      - containerPort: 80
        hostPort: 80
        name: lb-tcp-80
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    - env:
      - name: SRC_PORT
        value: "443"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "443"
      - name: DEST_IPS
        value: 10.43.51.248
      image: rancher/klipper-lb:v0.4.4
      imagePullPolicy: IfNotPresent
      name: lb-tcp-443
      ports:
      - containerPort: 443
        hostPort: 443
        name: lb-tcp-443
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      sysctls:
      - name: net.ipv4.ip_forward
        value: "1"
    serviceAccount: svclb
    serviceAccountName: svclb
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3f5433ce8423f09da5e8f94147a5bf048dbcaa2280edd498ed0bfb7bced18b9b
      image: docker.io/rancher/klipper-lb:v0.4.4
      imageID: docker.io/rancher/klipper-lb@sha256:d6780e97ac25454b56f88410b236d52572518040f11d0db5c6baaac0d2fcf860
      lastState: {}
      name: lb-tcp-443
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:25:57Z"
    - containerID: containerd://aa6917b09f0f644ba02e82352663fe1bdbc370de7b75d36f85d16566fe25c55e
      image: docker.io/rancher/klipper-lb:v0.4.4
      imageID: docker.io/rancher/klipper-lb@sha256:d6780e97ac25454b56f88410b236d52572518040f11d0db5c6baaac0d2fcf860
      lastState: {}
      name: lb-tcp-80
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:25:57Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.7
    podIPs:
    - ip: 10.42.0.7
    qosClass: BestEffort
    startTime: "2025-08-13T16:25:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      helmcharts.helm.cattle.io/configHash: SHA256=38EF8D37A494EC895F55E5B340E99DD0C12D75DDBBB11C66A2C5946E4702F0F8
    creationTimestamp: "2025-08-13T16:25:45Z"
    generateName: helm-install-traefik-
    labels:
      batch.kubernetes.io/controller-uid: c4b71a4e-77be-4918-bf4d-3dc3d4553034
      batch.kubernetes.io/job-name: helm-install-traefik
      controller-uid: c4b71a4e-77be-4918-bf4d-3dc3d4553034
      helmcharts.helm.cattle.io/chart: traefik
      job-name: helm-install-traefik
    name: helm-install-traefik-z48rc
    namespace: kube-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-traefik
      uid: c4b71a4e-77be-4918-bf4d-3dc3d4553034
    resourceVersion: "645"
    uid: 487b083e-232d-4070-b1e8-aa05811b598e
  spec:
    containers:
    - args:
      - install
      - --set-string
      - global.systemDefaultRegistry=
      env:
      - name: NAME
        value: traefik
      - name: VERSION
      - name: REPO
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: kube-system
      - name: CHART
        value: https://%{KUBERNETES_API}%/static/charts/traefik-25.0.2+up25.0.0.tgz
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: kube-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.2-build20230815
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-22tdf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: helm-traefik
    serviceAccountName: helm-traefik
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-traefik
    - configMap:
        defaultMode: 420
        name: chart-content-traefik
      name: content
    - name: kube-api-access-22tdf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:57Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:57Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1c6eed7e5cc9f8540e4dff4ea29b945f32123d1717d1d81ccc4210a94a5e4dc2
      image: docker.io/rancher/klipper-helm:v0.8.2-build20230815
      imageID: docker.io/rancher/klipper-helm@sha256:b0b0c4f73f2391697edb52adffe4fc490de1c8590606024515bb906b2813554a
      lastState: {}
      name: helm
      ready: false
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: containerd://1c6eed7e5cc9f8540e4dff4ea29b945f32123d1717d1d81ccc4210a94a5e4dc2
          exitCode: 0
          finishedAt: "2025-08-13T16:25:57Z"
          message: |
            Installing helm_v3 chart
          reason: Completed
          startedAt: "2025-08-13T16:25:53Z"
    hostIP: 37.59.98.241
    phase: Succeeded
    podIP: 10.42.0.4
    podIPs:
    - ip: 10.42.0.4
    qosClass: BestEffort
    startTime: "2025-08-13T16:25:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9100"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:25:54Z"
    generateName: traefik-f4564c4f4-
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-25.0.2_up25.0.0
      pod-template-hash: f4564c4f4
    name: traefik-f4564c4f4-krszj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: traefik-f4564c4f4
      uid: aaab71ed-602c-4901-981e-5da317407d3c
    resourceVersion: "650"
    uid: 91c36372-47c6-47c1-96be-4c8eefc70572
  spec:
    containers:
    - args:
      - --global.checknewversion
      - --global.sendanonymoususage
      - --entrypoints.metrics.address=:9100/tcp
      - --entrypoints.traefik.address=:9000/tcp
      - --entrypoints.web.address=:8000/tcp
      - --entrypoints.websecure.address=:8443/tcp
      - --api.dashboard=true
      - --ping=true
      - --metrics.prometheus=true
      - --metrics.prometheus.entrypoint=metrics
      - --providers.kubernetescrd
      - --providers.kubernetesingress
      - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
      - --entrypoints.websecure.http.tls=true
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/mirrored-library-traefik:2.10.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /ping
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      name: traefik
      ports:
      - containerPort: 9100
        name: metrics
        protocol: TCP
      - containerPort: 9000
        name: traefik
        protocol: TCP
      - containerPort: 8000
        name: web
        protocol: TCP
      - containerPort: 8443
        name: websecure
        protocol: TCP
      readinessProbe:
        failureThreshold: 1
        httpGet:
          path: /ping
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /data
        name: data
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-69hfh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroupChangePolicy: OnRootMismatch
      runAsGroup: 65532
      runAsNonRoot: true
      runAsUser: 65532
    serviceAccount: traefik
    serviceAccountName: traefik
    terminationGracePeriodSeconds: 60
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: data
    - emptyDir: {}
      name: tmp
    - name: kube-api-access-69hfh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:26:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:26:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://8ac2507cfcd0422fdc2836a298d82d8efa4a2b89c51e81d05efd8e89fa211272
      image: docker.io/rancher/mirrored-library-traefik:2.10.5
      imageID: docker.io/rancher/mirrored-library-traefik@sha256:ca9c8fbe001070c546a75184e3fd7f08c3e47dfc1e89bff6fe2edd302accfaec
      lastState: {}
      name: traefik
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:25:58Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.8
    podIPs:
    - ip: 10.42.0.8
    qosClass: BestEffort
    startTime: "2025-08-13T16:25:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:25:45Z"
    generateName: metrics-server-67c658944b-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 67c658944b
    name: metrics-server-67c658944b-vhxgt
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-67c658944b
      uid: 38c66807-54da-4d14-845e-bbe77a167850
    resourceVersion: "660"
    uid: a06f8d13-c7a9-43f4-a5aa-fa612eff3966
  spec:
    containers:
    - args:
      - --cert-dir=/tmp
      - --secure-port=10250
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
      image: rancher/mirrored-metrics-server:v0.6.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: https
          scheme: HTTPS
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: metrics-server
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: https
          scheme: HTTPS
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pjk4j
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-pjk4j
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:26:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:26:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:25:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f370722f8d4e28722c4a3fce2327f68129cff742a6b2f29adfbecc3c50b17a0e
      image: docker.io/rancher/mirrored-metrics-server:v0.6.3
      imageID: docker.io/rancher/mirrored-metrics-server@sha256:c2dfd72bafd6406ed306d9fbd07f55c496b004293d13d3de88a4567eacc36558
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:25:50Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.3
    podIPs:
    - ip: 10.42.0.3
    qosClass: Burstable
    startTime: "2025-08-13T16:25:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:31:59Z"
    generateName: cert-manager-cainjector-d7f8b5464-
    labels:
      app: cainjector
      app.kubernetes.io/component: cainjector
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: cainjector
      app.kubernetes.io/version: v1.13.3
      helm.sh/chart: cert-manager-v1.13.3
      pod-template-hash: d7f8b5464
    name: cert-manager-cainjector-d7f8b5464-2bjf8
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-cainjector-d7f8b5464
      uid: 01dbdd0f-d877-4ce5-812c-f1d6d12a05d6
    resourceVersion: "918"
    uid: dea83862-c89c-461e-8e45-fabbb02cd488
  spec:
    containers:
    - args:
      - --v=2
      - --leader-election-namespace=kube-system
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-cainjector:v1.13.3
      imagePullPolicy: IfNotPresent
      name: cert-manager-cainjector
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ns6f9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager-cainjector
    serviceAccountName: cert-manager-cainjector
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-ns6f9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:31:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:32:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:32:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:31:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://67f1d489b6dc56e6f3f022b2151d8875a86bd5de789e3f001617263b7bf6584b
      image: quay.io/jetstack/cert-manager-cainjector:v1.13.3
      imageID: quay.io/jetstack/cert-manager-cainjector@sha256:ac5154525f99bd0872671613741aac1b7dcb9c0df988571a7618155ddb6fabd2
      lastState: {}
      name: cert-manager-cainjector
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:32:02Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.10
    podIPs:
    - ip: 10.42.0.10
    qosClass: BestEffort
    startTime: "2025-08-13T16:31:59Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9402"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:31:59Z"
    generateName: cert-manager-57688f5dc6-
    labels:
      app: cert-manager
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: cert-manager
      app.kubernetes.io/version: v1.13.3
      helm.sh/chart: cert-manager-v1.13.3
      pod-template-hash: 57688f5dc6
    name: cert-manager-57688f5dc6-t4kbl
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-57688f5dc6
      uid: 6bb932b1-bfcc-4637-b49f-b51461ca2ade
    resourceVersion: "920"
    uid: d45e1d98-bffe-41ab-a916-a102020e7539
  spec:
    containers:
    - args:
      - --v=2
      - --cluster-resource-namespace=$(POD_NAMESPACE)
      - --leader-election-namespace=kube-system
      - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.13.3
      - --max-concurrent-challenges=60
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-controller:v1.13.3
      imagePullPolicy: IfNotPresent
      name: cert-manager-controller
      ports:
      - containerPort: 9402
        name: http-metrics
        protocol: TCP
      - containerPort: 9403
        name: http-healthz
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9rzr4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager
    serviceAccountName: cert-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-9rzr4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:31:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:32:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:32:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:31:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fe2cbd752419cfaaba1d717277e871b20256a97b71e985e2bd8e440a6633e939
      image: quay.io/jetstack/cert-manager-controller:v1.13.3
      imageID: quay.io/jetstack/cert-manager-controller@sha256:2121d4250f5734ee097df243507d06536fc264140dba3425045a825ef597c79d
      lastState: {}
      name: cert-manager-controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:32:02Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.9
    podIPs:
    - ip: 10.42.0.9
    qosClass: BestEffort
    startTime: "2025-08-13T16:31:59Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:31:59Z"
    generateName: cert-manager-webhook-58fd67545d-
    labels:
      app: webhook
      app.kubernetes.io/component: webhook
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: webhook
      app.kubernetes.io/version: v1.13.3
      helm.sh/chart: cert-manager-v1.13.3
      pod-template-hash: 58fd67545d
    name: cert-manager-webhook-58fd67545d-skpc6
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-webhook-58fd67545d
      uid: 65606f80-7a06-470f-ba35-e74beb59ba33
    resourceVersion: "939"
    uid: b4cd3c8a-c75d-471c-a26d-56798bc012dc
  spec:
    containers:
    - args:
      - --v=2
      - --secure-port=10250
      - --dynamic-serving-ca-secret-namespace=$(POD_NAMESPACE)
      - --dynamic-serving-ca-secret-name=cert-manager-webhook-ca
      - --dynamic-serving-dns-names=cert-manager-webhook
      - --dynamic-serving-dns-names=cert-manager-webhook.$(POD_NAMESPACE)
      - --dynamic-serving-dns-names=cert-manager-webhook.$(POD_NAMESPACE).svc
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-webhook:v1.13.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: 6080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: cert-manager-webhook
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      - containerPort: 6080
        name: healthcheck
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 6080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-64wrg
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager-webhook
    serviceAccountName: cert-manager-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-64wrg
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:31:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:32:09Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:32:09Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:31:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://0c638949a9254d41f5e71f1372e593a574ca82c35387c12c6e85aef879c26a2d
      image: quay.io/jetstack/cert-manager-webhook:v1.13.3
      imageID: quay.io/jetstack/cert-manager-webhook@sha256:f45b21f770bf4676c732f19e2ef17c34f46ac75873a5e0aa25703d808b2e5566
      lastState: {}
      name: cert-manager-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:32:02Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.11
    podIPs:
    - ip: 10.42.0.11
    qosClass: BestEffort
    startTime: "2025-08-13T16:31:59Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:33:11Z"
    generateName: kube-prometheus-stack-operator-84bb84b56b-
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 76.3.0
      chart: kube-prometheus-stack-76.3.0
      heritage: Helm
      pod-template-hash: 84bb84b56b
      release: kube-prometheus-stack
    name: kube-prometheus-stack-operator-84bb84b56b-lp5th
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-prometheus-stack-operator-84bb84b56b
      uid: b211b26c-5006-4549-b95b-fba8080943ef
    resourceVersion: "1365"
    uid: 136bcffc-8bcd-47da-afe0-540e6eadfd6a
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --kubelet-service=kube-system/kube-prometheus-stack-kubelet
      - --kubelet-endpoints=true
      - --kubelet-endpointslice=false
      - --localhost=127.0.0.1
      - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      - --config-reloader-cpu-request=0
      - --config-reloader-cpu-limit=0
      - --config-reloader-memory-request=0
      - --config-reloader-memory-limit=0
      - --thanos-default-base-image=quay.io/thanos/thanos:v0.39.2
      - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
      - --web.enable-tls=true
      - --web.cert-file=/cert/cert
      - --web.key-file=/cert/key
      - --web.listen-address=:10250
      - --web.tls-min-version=VersionTLS13
      env:
      - name: GOGC
        value: "30"
      image: quay.io/prometheus-operator/prometheus-operator:v0.84.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: kube-prometheus-stack
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /cert
        name: tls-secret
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mp67v
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-operator
    serviceAccountName: kube-prometheus-stack-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: tls-secret
      secret:
        defaultMode: 420
        secretName: kube-prometheus-stack-admission
    - name: kube-api-access-mp67v
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5d06849b6e143fc6154000aa44a2632b1584d1f050f4f33e24bd5191d10def8a
      image: quay.io/prometheus-operator/prometheus-operator:v0.84.1
      imageID: quay.io/prometheus-operator/prometheus-operator@sha256:07e77b3801a43716966529504b81f8883a8a753abfc0def4cb6ec33098155b06
      lastState: {}
      name: kube-prometheus-stack
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:15Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.15
    podIPs:
    - ip: 10.42.0.15
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2025-08-13T16:33:11Z"
    generateName: kube-prometheus-stack-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.9.1
      controller-revision-hash: 56cc96cfd7
      helm.sh/chart: prometheus-node-exporter-4.47.3
      jobLabel: node-exporter
      pod-template-generation: "1"
      release: kube-prometheus-stack
    name: kube-prometheus-stack-prometheus-node-exporter-62sjs
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-prometheus-stack-prometheus-node-exporter
      uid: 4e82d79c-f1ac-4a46-bfd2-b7ad049ee20c
    resourceVersion: "1369"
    uid: 44abc729-5c55-4e70-93b3-b32e6c68d11a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - vps-6227e9e1
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs|erofs)$
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.9.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http-metrics
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: http-metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http-metrics
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: kube-prometheus-stack-prometheus-node-exporter
    serviceAccountName: kube-prometheus-stack-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7c595ec85a44e014509edec988827a95383a743de81cf45c2254d7ee086331ca
      image: quay.io/prometheus/node-exporter:v1.9.1
      imageID: quay.io/prometheus/node-exporter@sha256:d00a542e409ee618a4edc67da14dd48c5da66726bbd5537ab2af9c1dfc442c8a
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:14Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 37.59.98.241
    podIPs:
    - ip: 37.59.98.241
    - ip: 2001:41d0:304:200::233d
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T16:33:11Z"
    generateName: kube-prometheus-stack-kube-state-metrics-66bbcbc545-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.16.0
      helm.sh/chart: kube-state-metrics-6.1.4
      pod-template-hash: 66bbcbc545
      release: kube-prometheus-stack
    name: kube-prometheus-stack-kube-state-metrics-66bbcbc545-ldj4r
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-prometheus-stack-kube-state-metrics-66bbcbc545
      uid: 7df6a3b8-6075-4022-92b8-9c3fc31b6b22
    resourceVersion: "1454"
    uid: 3ea39be4-eb10-47fb-8b7c-04ea6efd51a3
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --port=8080
      - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kube-state-metrics
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6k97h
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-kube-state-metrics
    serviceAccountName: kube-prometheus-stack-kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-6k97h
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://21b1e87b8869bdc842395336f8e15eff39880a0694839e8895fea7c75cdc9bef
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0
      imageID: registry.k8s.io/kube-state-metrics/kube-state-metrics@sha256:e750cd4b43f782e3106537026c2995cac85d921aedea334e1d16caad7877c360
      lastState: {}
      name: kube-state-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:13Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.14
    podIPs:
    - ip: 10.42.0.14
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2025-08-13T16:33:15Z"
    generateName: alertmanager-kube-prometheus-stack-alertmanager-
    labels:
      alertmanager: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: kube-prometheus-stack-alertmanager
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: 0.28.1
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: alertmanager-kube-prometheus-stack-alertmanager-5d4b6986c8
      statefulset.kubernetes.io/pod-name: alertmanager-kube-prometheus-stack-alertmanager-0
    name: alertmanager-kube-prometheus-stack-alertmanager-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-kube-prometheus-stack-alertmanager
      uid: c3ac3864-31db-432a-a470-bee489283583
    resourceVersion: "1508"
    uid: 89a549c6-ee2e-4c7b-bb1f-d33c7a77cd33
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - alertmanager
              - key: alertmanager
                operator: In
                values:
                - kube-prometheus-stack-alertmanager
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=
      - --web.listen-address=:9093
      - --web.external-url=http://kube-prometheus-stack-alertmanager.monitoring:9093
      - --web.route-prefix=/
      - --cluster.label=monitoring/kube-prometheus-stack-alertmanager
      - --cluster.peer=alertmanager-kube-prometheus-stack-alertmanager-0.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/prometheus/alertmanager:v0.28.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: http-web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-kube-prometheus-stack-alertmanager-db
      - mountPath: /etc/alertmanager/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /etc/alertmanager/cluster_tls_config/cluster-tls-config.yaml
        name: cluster-tls-config
        readOnly: true
        subPath: cluster-tls-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xfd84
        readOnly: true
    - args:
      - --listen-address=:8080
      - --web-config-file=/etc/alertmanager/web_config/web-config.yaml
      - --reload-url=http://127.0.0.1:9093/-/reload
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /etc/alertmanager/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xfd84
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-kube-prometheus-stack-alertmanager-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8081
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8081
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /etc/alertmanager/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xfd84
        readOnly: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-alertmanager
    serviceAccountName: kube-prometheus-stack-alertmanager
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-prometheus-stack-alertmanager-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-kube-prometheus-stack-alertmanager-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - name: web-config
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-prometheus-stack-alertmanager-web-config
    - name: cluster-tls-config
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-prometheus-stack-alertmanager-cluster-tls-config
    - emptyDir: {}
      name: alertmanager-kube-prometheus-stack-alertmanager-db
    - name: kube-api-access-xfd84
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:17Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ff646951328eb459840ef5b9266431d58eb1b152d7fa61ef4f593418947f0d4c
      image: quay.io/prometheus/alertmanager:v0.28.1
      imageID: quay.io/prometheus/alertmanager@sha256:27c475db5fb156cab31d5c18a4251ac7ed567746a2483ff264516437a39b15ba
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:19Z"
    - containerID: containerd://e69e7e06c324885001105aa9a8fe93bacd93f70d5bc29674dad01adde55fce21
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:f9e2a3b8550b0b643c285fc45132fde845910012db6d850d3e04dd462db037b4
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:19Z"
    hostIP: 37.59.98.241
    initContainerStatuses:
    - containerID: containerd://3054fef9e0f00707b52afb77995f1469c589ea23e38b158821228f4717d52c54
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:f9e2a3b8550b0b643c285fc45132fde845910012db6d850d3e04dd462db037b4
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://3054fef9e0f00707b52afb77995f1469c589ea23e38b158821228f4717d52c54
          exitCode: 0
          finishedAt: "2025-08-13T16:33:17Z"
          reason: Completed
          startedAt: "2025-08-13T16:33:17Z"
    phase: Running
    podIP: 10.42.0.18
    podIPs:
    - ip: 10.42.0.18
    qosClass: Burstable
    startTime: "2025-08-13T16:33:15Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2025-08-13T16:33:15Z"
    generateName: prometheus-kube-prometheus-stack-prometheus-
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack-prometheus
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/version: 3.5.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: prometheus-kube-prometheus-stack-prometheus-85c497677f
      operator.prometheus.io/name: kube-prometheus-stack-prometheus
      operator.prometheus.io/shard: "0"
      prometheus: kube-prometheus-stack-prometheus
      statefulset.kubernetes.io/pod-name: prometheus-kube-prometheus-stack-prometheus-0
    name: prometheus-kube-prometheus-stack-prometheus-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-kube-prometheus-stack-prometheus
      uid: 8312e762-2cf9-4b0c-a232-9953e29170e4
    resourceVersion: "1565"
    uid: ca4ee297-2599-4081-9c1c-0572223a0db2
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - prometheus
              - key: app.kubernetes.io/instance
                operator: In
                values:
                - kube-prometheus-stack-prometheus
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --web.enable-lifecycle
      - --web.external-url=http://kube-prometheus-stack-prometheus.monitoring:9090
      - --web.route-prefix=/
      - --storage.tsdb.retention.time=30d
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.wal-compression
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: quay.io/prometheus/prometheus:v3.5.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: http-web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-kube-prometheus-stack-prometheus-db
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4xv7z
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4xv7z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-kube-prometheus-stack-prometheus-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8081
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8081
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4xv7z
        readOnly: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-prometheus
    serviceAccountName: kube-prometheus-stack-prometheus
    shareProcessNamespace: false
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: prometheus-kube-prometheus-stack-prometheus-db
      persistentVolumeClaim:
        claimName: prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-kube-prometheus-stack-prometheus
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-kube-prometheus-stack-prometheus-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-kube-prometheus-stack-prometheus-web-config
    - name: kube-api-access-4xv7z
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://023e68c06586343d13ba6ff03b346e2aaba0fcd40022a9693322a6c1eae76ffb
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:f9e2a3b8550b0b643c285fc45132fde845910012db6d850d3e04dd462db037b4
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:26Z"
    - containerID: containerd://4e848f61a0558ef9a24ba3491581e3af7698f55bff85aede347835a10f50e3d1
      image: quay.io/prometheus/prometheus:v3.5.0
      imageID: quay.io/prometheus/prometheus@sha256:63805ebb8d2b3920190daf1cb14a60871b16fd38bed42b857a3182bc621f4996
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:26Z"
    hostIP: 37.59.98.241
    initContainerStatuses:
    - containerID: containerd://5071095ccef93003b877f303c332545bbf22d533e3bceb0ea27612d71b1e4396
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.84.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:f9e2a3b8550b0b643c285fc45132fde845910012db6d850d3e04dd462db037b4
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://5071095ccef93003b877f303c332545bbf22d533e3bceb0ea27612d71b1e4396
          exitCode: 0
          finishedAt: "2025-08-13T16:33:20Z"
          reason: Completed
          startedAt: "2025-08-13T16:33:20Z"
    phase: Running
    podIP: 10.42.0.21
    podIPs:
    - ip: 10.42.0.21
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:19Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0f49fcd7a8fab642f9644e0a4d67b9f2bf9ce3e2cbf1f2ebfa7a301dbd59a7e0
    creationTimestamp: "2025-08-13T16:33:25Z"
    generateName: loki-promtail-
    labels:
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: promtail
      controller-revision-hash: 55567ff548
      pod-template-generation: "1"
    name: loki-promtail-5jlp2
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: loki-promtail
      uid: d5a17131-427d-43eb-ad7c-7a0e7e3d9027
    resourceVersion: "1595"
    uid: 6c9b6016-7a56-450a-9b78-504120fe9675
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - vps-6227e9e1
    containers:
    - args:
      - -config.file=/etc/promtail/promtail.yaml
      env:
      - name: HOSTNAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: docker.io/grafana/promtail:2.9.3
      imagePullPolicy: IfNotPresent
      name: promtail
      ports:
      - containerPort: 3101
        name: http-metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 5
        httpGet:
          path: /ready
          port: http-metrics
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/promtail
        name: config
      - mountPath: /run/promtail
        name: run
      - mountPath: /var/lib/docker/containers
        name: containers
        readOnly: true
      - mountPath: /var/log/pods
        name: pods
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vgppx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsGroup: 0
      runAsUser: 0
    serviceAccount: loki-promtail
    serviceAccountName: loki-promtail
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: config
      secret:
        defaultMode: 420
        secretName: loki-promtail
    - hostPath:
        path: /run/promtail
        type: ""
      name: run
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: containers
    - hostPath:
        path: /var/log/pods
        type: ""
      name: pods
    - name: kube-api-access-vgppx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:25Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://19cdbd0ec6ab8d311b91f80c69e40b540cb1edd8457ec95a7e517ba5540aa981
      image: docker.io/grafana/promtail:2.9.3
      imageID: docker.io/grafana/promtail@sha256:b338a29de45ef8ffa96f882f3a36306b1e61262b2a560ff523e0e2633cccbbc4
      lastState: {}
      name: promtail
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:30Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.22
    podIPs:
    - ip: 10.42.0.22
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:25Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
      checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
      checksum/secret: 032056e9c62bbe9d1daa41ee49cd3d9524c076f51ca4c65adadf4ef08ef28712
      kubectl.kubernetes.io/default-container: grafana
    creationTimestamp: "2025-08-13T16:33:11Z"
    generateName: kube-prometheus-stack-grafana-569c787945-
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 12.1.0
      helm.sh/chart: grafana-9.3.2
      pod-template-hash: 569c787945
    name: kube-prometheus-stack-grafana-569c787945-tkc4p
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-prometheus-stack-grafana-569c787945
      uid: 2a3e9017-6edd-4f1a-af79-0ab8e5e048ad
    resourceVersion: "1623"
    uid: 528cd835-49a2-41af-b462-df2ce7afa059
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_dashboard
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /tmp/dashboards
      - name: RESOURCE
        value: both
      - name: NAMESPACE
        value: ALL
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: kube-prometheus-stack-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: kube-prometheus-stack-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/dashboards/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.30.3
      imagePullPolicy: IfNotPresent
      name: grafana-sc-dashboard
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5rvfv
        readOnly: true
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_datasource
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /etc/grafana/provisioning/datasources
      - name: RESOURCE
        value: both
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: kube-prometheus-stack-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: kube-prometheus-stack-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/datasources/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.30.3
      imagePullPolicy: IfNotPresent
      name: grafana-sc-datasources
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5rvfv
        readOnly: true
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_SECURITY_ADMIN_USER
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: kube-prometheus-stack-grafana
      - name: GF_SECURITY_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: kube-prometheus-stack-grafana
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      image: docker.io/grafana/grafana:12.1.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      - containerPort: 6060
        name: profiling
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
        name: sc-dashboard-provider
        subPath: provider.yaml
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5rvfv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - command:
      - chown
      - -R
      - 472:472
      - /var/lib/grafana
      image: docker.io/library/busybox:1.31.1
      imagePullPolicy: IfNotPresent
      name: init-chown-data
      resources: {}
      securityContext:
        capabilities:
          add:
          - CHOWN
          drop:
          - ALL
        readOnlyRootFilesystem: false
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5rvfv
        readOnly: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 472
      runAsGroup: 472
      runAsNonRoot: true
      runAsUser: 472
    serviceAccount: kube-prometheus-stack-grafana
    serviceAccountName: kube-prometheus-stack-grafana
    shareProcessNamespace: false
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-prometheus-stack-grafana
      name: config
    - name: storage
      persistentVolumeClaim:
        claimName: kube-prometheus-stack-grafana
    - emptyDir: {}
      name: sc-dashboard-volume
    - configMap:
        defaultMode: 420
        name: kube-prometheus-stack-grafana-config-dashboards
      name: sc-dashboard-provider
    - emptyDir: {}
      name: sc-datasources-volume
    - name: kube-api-access-5rvfv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:21Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:18Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c811cf63e5e66e2a035ee6cead8a09cbbca5e6e5d048cbf685a1e227292b5732
      image: docker.io/grafana/grafana:12.1.0
      imageID: docker.io/grafana/grafana@sha256:6ac590e7cabc2fbe8d7b8fc1ce9c9f0582177b334e0df9c927ebd9670469440f
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:36Z"
    - containerID: containerd://da885d4b54e52aeaf09ba39b5ddcd7d20e728a0f31b67c567dd725741d299ff0
      image: quay.io/kiwigrid/k8s-sidecar:1.30.3
      imageID: quay.io/kiwigrid/k8s-sidecar@sha256:49dcce269568b1645b0050f296da787c99119647965229919a136614123f0627
      lastState: {}
      name: grafana-sc-dashboard
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:25Z"
    - containerID: containerd://4e33623f415e16ab586239cfa64a8ced4353a3acf6c008aff989065783811c5f
      image: quay.io/kiwigrid/k8s-sidecar:1.30.3
      imageID: quay.io/kiwigrid/k8s-sidecar@sha256:49dcce269568b1645b0050f296da787c99119647965229919a136614123f0627
      lastState: {}
      name: grafana-sc-datasources
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:25Z"
    hostIP: 37.59.98.241
    initContainerStatuses:
    - containerID: containerd://fccd471e008189195c7017112d40f5e055fddb1781989c9ed1b3b8e73dda5362
      image: docker.io/library/busybox:1.31.1
      imageID: docker.io/library/busybox@sha256:95cf004f559831017cdf4628aaf1bb30133677be8702a8c5f2994629f637a209
      lastState: {}
      name: init-chown-data
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://fccd471e008189195c7017112d40f5e055fddb1781989c9ed1b3b8e73dda5362
          exitCode: 0
          finishedAt: "2025-08-13T16:33:20Z"
          reason: Completed
          startedAt: "2025-08-13T16:33:20Z"
    phase: Running
    podIP: 10.42.0.20
    podIPs:
    - ip: 10.42.0.20
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:18Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 8543d68a9795066423a4ce0ff28f2c56950acfa1bac20e850c016a4fd91a9300
      prometheus.io/port: http-metrics
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:33:25Z"
    generateName: loki-
    labels:
      app: loki
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: loki-586959cb68
      name: loki
      release: loki
      statefulset.kubernetes.io/pod-name: loki-0
    name: loki-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: loki
      uid: ad880e5f-bba6-43d6-8805-b1b606ff1f24
    resourceVersion: "1716"
    uid: 7fe2276c-051d-4dfb-861b-4ffac07c5668
  spec:
    affinity: {}
    containers:
    - args:
      - -config.file=/etc/loki/loki.yaml
      image: grafana/loki:2.6.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: http-metrics
          scheme: HTTP
        initialDelaySeconds: 45
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: loki
      ports:
      - containerPort: 3100
        name: http-metrics
        protocol: TCP
      - containerPort: 9095
        name: grpc
        protocol: TCP
      - containerPort: 7946
        name: memberlist-port
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: http-metrics
          scheme: HTTP
        initialDelaySeconds: 45
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /etc/loki
        name: config
      - mountPath: /data
        name: storage
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xct8f
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: loki-0
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001
    serviceAccount: loki
    serviceAccountName: loki
    subdomain: loki-headless
    terminationGracePeriodSeconds: 4800
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: storage-loki-0
    - emptyDir: {}
      name: tmp
    - name: config
      secret:
        defaultMode: 420
        secretName: loki
    - name: kube-api-access-xct8f
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:34:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:34:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:33:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4333fecb714a9660527e210fbde0610ddd095cc0b79fb99c873641132c43e442
      image: docker.io/grafana/loki:2.6.1
      imageID: docker.io/grafana/loki@sha256:1ee60f980950b00e505bd564b40f720132a0653b110e993043bb5940673d060a
      lastState: {}
      name: loki
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:33:33Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.24
    podIPs:
    - ip: 10.42.0.24
    qosClass: BestEffort
    startTime: "2025-08-13T16:33:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:38:24Z"
    generateName: kustomize-controller-6556fc5b7b-
    labels:
      app: kustomize-controller
      pod-template-hash: 6556fc5b7b
    name: kustomize-controller-6556fc5b7b-qzm7n
    namespace: flux-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kustomize-controller-6556fc5b7b
      uid: 260628c9-61f1-4320-b64b-16110d9f12e4
    resourceVersion: "2148"
    uid: 7bf8fd60-3306-4417-8675-832f870b7bc4
  spec:
    containers:
    - args:
      - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
      - --watch-all-namespaces=true
      - --log-level=info
      - --log-encoding=json
      - --enable-leader-election
      env:
      - name: RUNTIME_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: GOMAXPROCS
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.cpu
      - name: GOMEMLIMIT
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.memory
      image: ghcr.io/fluxcd/kustomize-controller:v1.6.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: manager
      ports:
      - containerPort: 8080
        name: http-prom
        protocol: TCP
      - containerPort: 9440
        name: healthz
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: temp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-n55s4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1337
    serviceAccount: kustomize-controller
    serviceAccountName: kustomize-controller
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: temp
    - name: kube-api-access-n55s4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://05dbd5e9eed62eb029523d62dfe03e0a501cc4b9a29bccdf1dd2bc995a65bdb7
      image: ghcr.io/fluxcd/kustomize-controller:v1.6.1
      imageID: ghcr.io/fluxcd/kustomize-controller@sha256:1a50730537bafb7827365b9af95c4eb71ca3d9b0bed9bc9bc765880e976972ef
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:38:28Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.29
    podIPs:
    - ip: 10.42.0.29
    qosClass: Burstable
    startTime: "2025-08-13T16:38:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:38:24Z"
    generateName: source-controller-6bcb87949f-
    labels:
      app: source-controller
      pod-template-hash: 6bcb87949f
    name: source-controller-6bcb87949f-zkkl5
    namespace: flux-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: source-controller-6bcb87949f
      uid: ce0712d7-ebee-42f7-ad74-daa1c08d27ae
    resourceVersion: "2151"
    uid: dc0bc921-0d03-4fbc-8307-580b19364268
  spec:
    containers:
    - args:
      - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
      - --watch-all-namespaces=true
      - --log-level=info
      - --log-encoding=json
      - --enable-leader-election
      - --storage-path=/data
      - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
      env:
      - name: RUNTIME_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: TUF_ROOT
        value: /tmp/.sigstore
      - name: GOMAXPROCS
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.cpu
      - name: GOMEMLIMIT
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.memory
      image: ghcr.io/fluxcd/source-controller:v1.6.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: manager
      ports:
      - containerPort: 9090
        name: http
        protocol: TCP
      - containerPort: 8080
        name: http-prom
        protocol: TCP
      - containerPort: 9440
        name: healthz
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 50m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /data
        name: data
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pcrxf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1337
    serviceAccount: source-controller
    serviceAccountName: source-controller
    terminationGracePeriodSeconds: 10
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: data
    - emptyDir: {}
      name: tmp
    - name: kube-api-access-pcrxf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://dfc908d5b44017d32733c32b0a449d7aec9e46a366acfc941960f48fe178f4de
      image: ghcr.io/fluxcd/source-controller:v1.6.2
      imageID: ghcr.io/fluxcd/source-controller@sha256:11c8e14df885eff86586533d9941293ec8a1e9fff71bacf119edc79fdf3c63e3
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:38:28Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.31
    podIPs:
    - ip: 10.42.0.31
    qosClass: Burstable
    startTime: "2025-08-13T16:38:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:38:24Z"
    generateName: helm-controller-5f59f5f66b-
    labels:
      app: helm-controller
      pod-template-hash: 5f59f5f66b
    name: helm-controller-5f59f5f66b-phcfk
    namespace: flux-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: helm-controller-5f59f5f66b
      uid: 19b4f176-7437-4aa3-88dc-8b7e65ce3e42
    resourceVersion: "2156"
    uid: aeb22cfd-8975-4e5d-8cfd-81f0a438c3f8
  spec:
    containers:
    - args:
      - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
      - --watch-all-namespaces=true
      - --log-level=info
      - --log-encoding=json
      - --enable-leader-election
      env:
      - name: RUNTIME_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: GOMAXPROCS
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.cpu
      - name: GOMEMLIMIT
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.memory
      image: ghcr.io/fluxcd/helm-controller:v1.3.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: manager
      ports:
      - containerPort: 8080
        name: http-prom
        protocol: TCP
      - containerPort: 9440
        name: healthz
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: temp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-88r8q
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1337
    serviceAccount: helm-controller
    serviceAccountName: helm-controller
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: temp
    - name: kube-api-access-88r8q
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ab5955492dfdda09d13709ffb57ddd7a22cfc6d517a56d1a57e32f059fdb1b05
      image: ghcr.io/fluxcd/helm-controller:v1.3.0
      imageID: ghcr.io/fluxcd/helm-controller@sha256:db55d9d9f9b5106acd8c21da6916b8e285fcfc5572f214361ececd1a8571a4f0
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:38:28Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.26
    podIPs:
    - ip: 10.42.0.26
    qosClass: Burstable
    startTime: "2025-08-13T16:38:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:38:24Z"
    generateName: image-reflector-controller-68c8847f64-
    labels:
      app: image-reflector-controller
      pod-template-hash: 68c8847f64
    name: image-reflector-controller-68c8847f64-hcpzp
    namespace: flux-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: image-reflector-controller-68c8847f64
      uid: 04705579-1517-4838-8f5c-6b7da15250cc
    resourceVersion: "2159"
    uid: 59480ec7-23d5-4046-a4b9-59d3d337b7e5
  spec:
    containers:
    - args:
      - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
      - --watch-all-namespaces=true
      - --log-level=info
      - --log-encoding=json
      - --enable-leader-election
      env:
      - name: RUNTIME_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: GOMAXPROCS
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.cpu
      - name: GOMEMLIMIT
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.memory
      image: ghcr.io/fluxcd/image-reflector-controller:v0.35.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: manager
      ports:
      - containerPort: 8080
        name: http-prom
        protocol: TCP
      - containerPort: 9440
        name: healthz
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: temp
      - mountPath: /data
        name: data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pdcw4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1337
    serviceAccount: image-reflector-controller
    serviceAccountName: image-reflector-controller
    terminationGracePeriodSeconds: 10
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: temp
    - emptyDir: {}
      name: data
    - name: kube-api-access-pdcw4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:28Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://bfecc89a7459a9149e82974b47f8652273451c27ffd5a41b310ed6bc8640211b
      image: ghcr.io/fluxcd/image-reflector-controller:v0.35.2
      imageID: ghcr.io/fluxcd/image-reflector-controller@sha256:4df89798b23a1ba7ec86bab327dcb50417af1517fe7986e511e28f62f40b8f61
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:38:27Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.28
    podIPs:
    - ip: 10.42.0.28
    qosClass: Burstable
    startTime: "2025-08-13T16:38:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:38:24Z"
    generateName: notification-controller-fbc4b7bb7-
    labels:
      app: notification-controller
      pod-template-hash: fbc4b7bb7
    name: notification-controller-fbc4b7bb7-m99br
    namespace: flux-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: notification-controller-fbc4b7bb7
      uid: 2108996f-6aca-44e8-88aa-687c8a2f30b1
    resourceVersion: "2180"
    uid: 486f9e64-3f60-4efc-9661-7e6b2f7f57c4
  spec:
    containers:
    - args:
      - --watch-all-namespaces=true
      - --log-level=info
      - --log-encoding=json
      - --enable-leader-election
      env:
      - name: RUNTIME_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: GOMAXPROCS
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.cpu
      - name: GOMEMLIMIT
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.memory
      image: ghcr.io/fluxcd/notification-controller:v1.6.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: manager
      ports:
      - containerPort: 9090
        name: http
        protocol: TCP
      - containerPort: 9292
        name: http-webhook
        protocol: TCP
      - containerPort: 8080
        name: http-prom
        protocol: TCP
      - containerPort: 9440
        name: healthz
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: temp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v4w5v
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1337
    serviceAccount: notification-controller
    serviceAccountName: notification-controller
    terminationGracePeriodSeconds: 10
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: temp
    - name: kube-api-access-v4w5v
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://98bc20a5e40aeeb010e3fcb48cda819ae6e9317f8a69bfbeff84d1d687fae3f1
      image: ghcr.io/fluxcd/notification-controller:v1.6.0
      imageID: ghcr.io/fluxcd/notification-controller@sha256:80174ff676407af7a6feff67b0c2f100de9f7f89df4c26fc871e4d4c4006544d
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:38:28Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.30
    podIPs:
    - ip: 10.42.0.30
    qosClass: Burstable
    startTime: "2025-08-13T16:38:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-13T16:38:24Z"
    generateName: image-automation-controller-57f9cbdbd8-
    labels:
      app: image-automation-controller
      pod-template-hash: 57f9cbdbd8
    name: image-automation-controller-57f9cbdbd8-ccxgf
    namespace: flux-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: image-automation-controller-57f9cbdbd8
      uid: 5f3449b3-0bc5-46a5-8bef-26d260d1b712
    resourceVersion: "2185"
    uid: 881efef4-7816-4a88-9a43-dec89dc31ff4
  spec:
    containers:
    - args:
      - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
      - --watch-all-namespaces=true
      - --log-level=info
      - --log-encoding=json
      - --enable-leader-election
      env:
      - name: RUNTIME_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: GOMAXPROCS
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.cpu
      - name: GOMEMLIMIT
        valueFrom:
          resourceFieldRef:
            containerName: manager
            divisor: "0"
            resource: limits.memory
      image: ghcr.io/fluxcd/image-automation-controller:v0.41.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: manager
      ports:
      - containerPort: 8080
        name: http-prom
        protocol: TCP
      - containerPort: 9440
        name: healthz
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: healthz
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: temp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q5q27
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1337
    serviceAccount: image-automation-controller
    serviceAccountName: image-automation-controller
    terminationGracePeriodSeconds: 10
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: temp
    - name: kube-api-access-q5q27
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T16:38:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4343b7903aabe5b3445963f444108e6eb00abed4fe0b7665f1528436f0c8d281
      image: ghcr.io/fluxcd/image-automation-controller:v0.41.2
      imageID: ghcr.io/fluxcd/image-automation-controller@sha256:e5b90e065e0d91690dbcd83dab3d03207ed030b068e26e9dac88c8d7b4fdfbe4
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T16:38:29Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.27
    podIPs:
    - ip: 10.42.0.27
    qosClass: Burstable
    startTime: "2025-08-13T16:38:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-08-13T17:53:18Z"
    generateName: strimzi-cluster-operator-675759b959-
    labels:
      name: strimzi-cluster-operator
      pod-template-hash: 675759b959
      strimzi.io/kind: cluster-operator
    name: strimzi-cluster-operator-675759b959-2ptv8
    namespace: kafka
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: strimzi-cluster-operator-675759b959
      uid: 89152d14-3bda-4df2-a6d8-d69fdd0d94dd
    resourceVersion: "15933"
    uid: 68b4db9b-0371-4529-9639-aa629066b9ce
  spec:
    containers:
    - args:
      - /opt/strimzi/bin/cluster_operator_run.sh
      env:
      - name: STRIMZI_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS
        value: "120000"
      - name: STRIMZI_OPERATION_TIMEOUT_MS
        value: "300000"
      - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE
        value: quay.io/strimzi/kafka:0.43.0-kafka-3.8.0
      - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE
        value: quay.io/strimzi/kafka:0.43.0-kafka-3.8.0
      - name: STRIMZI_KAFKA_IMAGES
        value: |
          3.7.0=quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
          3.7.1=quay.io/strimzi/kafka:0.43.0-kafka-3.7.1
          3.8.0=quay.io/strimzi/kafka:0.43.0-kafka-3.8.0
      - name: STRIMZI_KAFKA_CONNECT_IMAGES
        value: |
          3.7.0=quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
          3.7.1=quay.io/strimzi/kafka:0.43.0-kafka-3.7.1
          3.8.0=quay.io/strimzi/kafka:0.43.0-kafka-3.8.0
      - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
        value: |
          3.7.0=quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
          3.7.1=quay.io/strimzi/kafka:0.43.0-kafka-3.7.1
          3.8.0=quay.io/strimzi/kafka:0.43.0-kafka-3.8.0
      - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
        value: |
          3.7.0=quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
          3.7.1=quay.io/strimzi/kafka:0.43.0-kafka-3.7.1
          3.8.0=quay.io/strimzi/kafka:0.43.0-kafka-3.8.0
      - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE
        value: quay.io/strimzi/operator:0.43.0
      - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE
        value: quay.io/strimzi/operator:0.43.0
      - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE
        value: quay.io/strimzi/operator:0.43.0
      - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE
        value: quay.io/strimzi/kafka-bridge:0.30.0
      - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE
        value: quay.io/strimzi/kaniko-executor:0.43.0
      - name: STRIMZI_DEFAULT_MAVEN_BUILDER
        value: quay.io/strimzi/maven-builder:0.43.0
      - name: STRIMZI_OPERATOR_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: STRIMZI_FEATURE_GATES
      - name: STRIMZI_LEADER_ELECTION_ENABLED
        value: "true"
      - name: STRIMZI_LEADER_ELECTION_LEASE_NAME
        value: strimzi-cluster-operator
      - name: STRIMZI_LEADER_ELECTION_LEASE_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: STRIMZI_LEADER_ELECTION_IDENTITY
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      image: quay.io/strimzi/operator:0.43.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthy
          port: http
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 1
      name: strimzi-cluster-operator
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: http
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 384Mi
        requests:
          cpu: 200m
          memory: 384Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: strimzi-tmp
      - mountPath: /opt/strimzi/custom-config/
        name: co-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rw5tm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: strimzi-cluster-operator
    serviceAccountName: strimzi-cluster-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
        sizeLimit: 1Mi
      name: strimzi-tmp
    - configMap:
        defaultMode: 420
        name: strimzi-cluster-operator
      name: co-config-volume
    - name: kube-api-access-rw5tm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T17:53:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T17:53:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T17:53:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T17:53:18Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://45ce8fcf5f1c7a5c93065b58605f25c8da7075e9a45e90e93e087fcc2d05edc1
      image: quay.io/strimzi/operator:0.43.0
      imageID: quay.io/strimzi/operator@sha256:d3732245f34afaa6b571f1f912e1cd017891b22003d6367ae8ca059b2a5cb13c
      lastState: {}
      name: strimzi-cluster-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T17:53:18Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.76
    podIPs:
    - ip: 10.42.0.76
    qosClass: Burstable
    startTime: "2025-08-13T17:53:18Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      strimzi.io/cluster-ca-cert-generation: "0"
      strimzi.io/cluster-ca-key-generation: "0"
      strimzi.io/logging-hash: 0f057cb0
      strimzi.io/revision: a639514b
      strimzi.io/server-cert-hash: d016e3d651ce152115b0ce60ac2e699899e7fd2f
    creationTimestamp: "2025-08-13T18:22:38Z"
    labels:
      app.kubernetes.io/instance: mercurious-cluster
      app.kubernetes.io/managed-by: strimzi-cluster-operator
      app.kubernetes.io/name: zookeeper
      app.kubernetes.io/part-of: strimzi-mercurious-cluster
      statefulset.kubernetes.io/pod-name: mercurious-cluster-zookeeper-0
      strimzi.io/cluster: mercurious-cluster
      strimzi.io/component-type: zookeeper
      strimzi.io/controller: strimzipodset
      strimzi.io/controller-name: mercurious-cluster-zookeeper
      strimzi.io/kind: Kafka
      strimzi.io/name: mercurious-cluster-zookeeper
      strimzi.io/pod-name: mercurious-cluster-zookeeper-0
    name: mercurious-cluster-zookeeper-0
    namespace: kafka
    ownerReferences:
    - apiVersion: core.strimzi.io/v1beta2
      blockOwnerDeletion: false
      controller: true
      kind: StrimziPodSet
      name: mercurious-cluster-zookeeper
      uid: e26e1737-f47d-49d0-a6c5-247bfd03c5ec
    resourceVersion: "21586"
    uid: 4a587e67-6654-4425-9864-692d2c260b93
  spec:
    containers:
    - args:
      - /opt/kafka/zookeeper_run.sh
      env:
      - name: ZOOKEEPER_METRICS_ENABLED
        value: "false"
      - name: ZOOKEEPER_SNAPSHOT_CHECK_ENABLED
        value: "true"
      - name: STRIMZI_KAFKA_GC_LOG_ENABLED
        value: "false"
      - name: STRIMZI_DYNAMIC_HEAP_PERCENTAGE
        value: "75"
      - name: STRIMZI_DYNAMIC_HEAP_MAX
        value: "2147483648"
      - name: ZOOKEEPER_CONFIGURATION
        value: |
          tickTime=2000
          initLimit=5
          syncLimit=2
          autopurge.purgeInterval=1
          admin.enableServer=false
      image: quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /opt/kafka/zookeeper_healthcheck.sh
        failureThreshold: 3
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: zookeeper
      ports:
      - containerPort: 2888
        name: tcp-clustering
        protocol: TCP
      - containerPort: 3888
        name: tcp-election
        protocol: TCP
      - containerPort: 2181
        name: tcp-clients
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /opt/kafka/zookeeper_healthcheck.sh
        failureThreshold: 3
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 250m
          memory: 512Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: strimzi-tmp
      - mountPath: /var/lib/zookeeper
        name: data
      - mountPath: /opt/kafka/custom-config/
        name: zookeeper-metrics-and-logging
      - mountPath: /opt/kafka/zookeeper-node-certs/
        name: zookeeper-nodes
      - mountPath: /opt/kafka/cluster-ca-certs/
        name: cluster-ca-certs
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-crrsl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: mercurious-cluster-zookeeper-0
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
    serviceAccount: mercurious-cluster-zookeeper
    serviceAccountName: mercurious-cluster-zookeeper
    subdomain: mercurious-cluster-zookeeper-nodes
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
        sizeLimit: 5Mi
      name: strimzi-tmp
    - configMap:
        defaultMode: 420
        name: mercurious-cluster-zookeeper-config
      name: zookeeper-metrics-and-logging
    - name: zookeeper-nodes
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-zookeeper-nodes
    - name: cluster-ca-certs
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-cluster-ca-cert
    - name: data
      persistentVolumeClaim:
        claimName: data-mercurious-cluster-zookeeper-0
    - name: kube-api-access-crrsl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:22:42Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:22:42Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6e2fd1d1a0623eeb1d35222f0325a824bb0d45cd9e19f90b0496de000598f5d1
      image: quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
      imageID: quay.io/strimzi/kafka@sha256:d27cf5bf3624e18ba705246b14f92d12b8a15eb8551b13abf027cf71b549baf0
      lastState: {}
      name: zookeeper
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T18:22:43Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.99
    podIPs:
    - ip: 10.42.0.99
    qosClass: Burstable
    startTime: "2025-08-13T18:22:42Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      strimzi.io/broker-configuration-hash: f328b696
      strimzi.io/clients-ca-cert-generation: "0"
      strimzi.io/cluster-ca-cert-generation: "0"
      strimzi.io/cluster-ca-key-generation: "0"
      strimzi.io/inter-broker-protocol-version: "3.7"
      strimzi.io/kafka-version: 3.7.0
      strimzi.io/log-message-format-version: "3.7"
      strimzi.io/logging-hash: e893ac9f
      strimzi.io/revision: 22c584be
      strimzi.io/server-cert-hash: 77aa99d9c673789135d48f5a1c8ae288b6e604ca
    creationTimestamp: "2025-08-13T18:23:06Z"
    labels:
      app.kubernetes.io/instance: mercurious-cluster
      app.kubernetes.io/managed-by: strimzi-cluster-operator
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: strimzi-mercurious-cluster
      statefulset.kubernetes.io/pod-name: mercurious-cluster-kafka-0
      strimzi.io/broker-role: "true"
      strimzi.io/cluster: mercurious-cluster
      strimzi.io/component-type: kafka
      strimzi.io/controller: strimzipodset
      strimzi.io/controller-name: mercurious-cluster-kafka
      strimzi.io/controller-role: "false"
      strimzi.io/kind: Kafka
      strimzi.io/name: mercurious-cluster-kafka
      strimzi.io/pod-name: mercurious-cluster-kafka-0
      strimzi.io/pool-name: kafka
    name: mercurious-cluster-kafka-0
    namespace: kafka
    ownerReferences:
    - apiVersion: core.strimzi.io/v1beta2
      blockOwnerDeletion: false
      controller: true
      kind: StrimziPodSet
      name: mercurious-cluster-kafka
      uid: 56b59239-38b7-4582-b3ba-ff91ed53a5ec
    resourceVersion: "21707"
    uid: 9d8200f5-772b-427a-a7a4-13aed9e39c9c
  spec:
    affinity: {}
    containers:
    - args:
      - /opt/kafka/kafka_run.sh
      env:
      - name: KAFKA_METRICS_ENABLED
        value: "false"
      - name: STRIMZI_KAFKA_GC_LOG_ENABLED
        value: "false"
      - name: STRIMZI_DYNAMIC_HEAP_PERCENTAGE
        value: "50"
      - name: STRIMZI_DYNAMIC_HEAP_MAX
        value: "5368709120"
      image: quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /opt/kafka/kafka_liveness.sh
        failureThreshold: 3
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kafka
      ports:
      - containerPort: 9090
        name: tcp-ctrlplane
        protocol: TCP
      - containerPort: 9091
        name: tcp-replication
        protocol: TCP
      - containerPort: 9092
        name: tcp-clients
        protocol: TCP
      - containerPort: 9093
        name: tcp-clientstls
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /opt/kafka/kafka_readiness.sh
        failureThreshold: 3
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          cpu: "1"
          memory: 4Gi
        requests:
          cpu: 500m
          memory: 2Gi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kafka/data
        name: data
      - mountPath: /tmp
        name: strimzi-tmp
      - mountPath: /opt/kafka/cluster-ca-certs
        name: cluster-ca
      - mountPath: /opt/kafka/broker-certs
        name: broker-certs
      - mountPath: /opt/kafka/client-ca-certs
        name: client-ca-cert
      - mountPath: /opt/kafka/custom-config/
        name: kafka-metrics-and-logging
      - mountPath: /var/opt/kafka
        name: ready-files
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jp5zz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: mercurious-cluster-kafka-0
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
    serviceAccount: mercurious-cluster-kafka
    serviceAccountName: mercurious-cluster-kafka
    subdomain: mercurious-cluster-kafka-brokers
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-mercurious-cluster-kafka-0
    - emptyDir:
        medium: Memory
        sizeLimit: 5Mi
      name: strimzi-tmp
    - name: cluster-ca
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-cluster-ca-cert
    - name: broker-certs
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-kafka-brokers
    - name: client-ca-cert
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-clients-ca-cert
    - configMap:
        defaultMode: 420
        name: mercurious-cluster-kafka-0
      name: kafka-metrics-and-logging
    - emptyDir:
        medium: Memory
        sizeLimit: 1Ki
      name: ready-files
    - name: kube-api-access-jp5zz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:30Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:30Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1e67294dcf301a536b8c61794b87486acb2a974c5f4aff0138720c0228e6b6a8
      image: quay.io/strimzi/kafka:0.43.0-kafka-3.7.0
      imageID: quay.io/strimzi/kafka@sha256:d27cf5bf3624e18ba705246b14f92d12b8a15eb8551b13abf027cf71b549baf0
      lastState: {}
      name: kafka
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T18:23:10Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.101
    podIPs:
    - ip: 10.42.0.101
    qosClass: Burstable
    startTime: "2025-08-13T18:23:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      strimzi.io/cluster-ca-cert-generation: "0"
      strimzi.io/cluster-ca-key-generation: "0"
      strimzi.io/server-cert-hash: db655280586dd3b3
    creationTimestamp: "2025-08-13T18:23:32Z"
    generateName: mercurious-cluster-entity-operator-79c5d7565d-
    labels:
      app.kubernetes.io/instance: mercurious-cluster
      app.kubernetes.io/managed-by: strimzi-cluster-operator
      app.kubernetes.io/name: entity-operator
      app.kubernetes.io/part-of: strimzi-mercurious-cluster
      pod-template-hash: 79c5d7565d
      strimzi.io/cluster: mercurious-cluster
      strimzi.io/component-type: entity-operator
      strimzi.io/kind: Kafka
      strimzi.io/name: mercurious-cluster-entity-operator
    name: mercurious-cluster-entity-operator-79c5d7565d-gb9hl
    namespace: kafka
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: mercurious-cluster-entity-operator-79c5d7565d
      uid: 8a806837-d4b3-4f17-81d3-9c7fc1ef3845
    resourceVersion: "21880"
    uid: c2aa7df3-d177-4250-b564-c535050e8cc5
  spec:
    containers:
    - args:
      - /opt/strimzi/bin/topic_operator_run.sh
      env:
      - name: STRIMZI_RESOURCE_LABELS
        value: strimzi.io/cluster=mercurious-cluster
      - name: STRIMZI_KAFKA_BOOTSTRAP_SERVERS
        value: mercurious-cluster-kafka-bootstrap:9091
      - name: STRIMZI_NAMESPACE
        value: kafka
      - name: STRIMZI_SECURITY_PROTOCOL
        value: SSL
      - name: STRIMZI_TLS_ENABLED
        value: "true"
      - name: STRIMZI_GC_LOG_ENABLED
        value: "false"
      image: quay.io/strimzi/operator:0.43.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthy
          port: healthcheck
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: topic-operator
      ports:
      - containerPort: 8080
        name: healthcheck
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: healthcheck
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          cpu: 200m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 512Mi
      startupProbe:
        failureThreshold: 12
        httpGet:
          path: /healthy
          port: healthcheck
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: strimzi-to-tmp
      - mountPath: /opt/topic-operator/custom-config/
        name: entity-topic-operator-metrics-and-logging
      - mountPath: /etc/eto-certs/
        name: eto-certs
      - mountPath: /etc/tls-sidecar/cluster-ca-certs/
        name: cluster-ca-certs
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jtzsg
        readOnly: true
    - args:
      - /opt/strimzi/bin/user_operator_run.sh
      env:
      - name: STRIMZI_KAFKA_BOOTSTRAP_SERVERS
        value: mercurious-cluster-kafka-bootstrap:9091
      - name: STRIMZI_NAMESPACE
        value: kafka
      - name: STRIMZI_LABELS
        value: strimzi.io/cluster=mercurious-cluster
      - name: STRIMZI_CA_KEY_NAME
        value: mercurious-cluster-clients-ca
      - name: STRIMZI_CA_CERT_NAME
        value: mercurious-cluster-clients-ca-cert
      - name: STRIMZI_CA_NAMESPACE
        value: kafka
      - name: STRIMZI_CA_VALIDITY
        value: "365"
      - name: STRIMZI_CA_RENEWAL
        value: "30"
      - name: STRIMZI_CLUSTER_CA_CERT_SECRET_NAME
        value: mercurious-cluster-cluster-ca-cert
      - name: STRIMZI_EO_KEY_SECRET_NAME
        value: mercurious-cluster-entity-user-operator-certs
      - name: STRIMZI_GC_LOG_ENABLED
        value: "false"
      - name: STRIMZI_SECRET_PREFIX
      - name: STRIMZI_ACLS_ADMIN_API_SUPPORTED
        value: "true"
      image: quay.io/strimzi/operator:0.43.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthy
          port: healthcheck
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: user-operator
      ports:
      - containerPort: 8081
        name: healthcheck
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: healthcheck
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          cpu: 200m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 512Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: strimzi-uo-tmp
      - mountPath: /opt/user-operator/custom-config/
        name: entity-user-operator-metrics-and-logging
      - mountPath: /etc/euo-certs/
        name: euo-certs
      - mountPath: /etc/tls-sidecar/cluster-ca-certs/
        name: cluster-ca-certs
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jtzsg
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: mercurious-cluster-entity-operator
    serviceAccountName: mercurious-cluster-entity-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: mercurious-cluster-entity-topic-operator-config
      name: entity-topic-operator-metrics-and-logging
    - emptyDir:
        medium: Memory
        sizeLimit: 5Mi
      name: strimzi-to-tmp
    - name: eto-certs
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-entity-topic-operator-certs
    - configMap:
        defaultMode: 420
        name: mercurious-cluster-entity-user-operator-config
      name: entity-user-operator-metrics-and-logging
    - emptyDir:
        medium: Memory
        sizeLimit: 5Mi
      name: strimzi-uo-tmp
    - name: euo-certs
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-entity-user-operator-certs
    - name: cluster-ca-certs
      secret:
        defaultMode: 292
        secretName: mercurious-cluster-cluster-ca-cert
    - name: kube-api-access-jtzsg
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:24:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:24:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:23:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://340f741cb673b233c3b8b8f4915ed726a8a7de77405914051e6808a9342c68bc
      image: quay.io/strimzi/operator:0.43.0
      imageID: quay.io/strimzi/operator@sha256:d3732245f34afaa6b571f1f912e1cd017891b22003d6367ae8ca059b2a5cb13c
      lastState: {}
      name: topic-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T18:23:32Z"
    - containerID: containerd://0288f804d1686e5127e18ac402aa2650e542ae27f5c6e5403599f3672d610978
      image: quay.io/strimzi/operator:0.43.0
      imageID: quay.io/strimzi/operator@sha256:d3732245f34afaa6b571f1f912e1cd017891b22003d6367ae8ca059b2a5cb13c
      lastState: {}
      name: user-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-13T18:23:32Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.102
    podIPs:
    - ip: 10.42.0.102
    qosClass: Burstable
    startTime: "2025-08-13T18:23:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"name":"kafka-client","namespace":"kafka"},"spec":{"containers":[{"command":["sleep","3600"],"image":"confluentinc/cp-kafka:7.4.0","name":"kafka"}],"restartPolicy":"Never"}}
    creationTimestamp: "2025-08-13T17:57:39Z"
    name: kafka-client
    namespace: kafka
    resourceVersion: "27231"
    uid: 6467bc92-4cda-4be6-89fe-31367daa4999
  spec:
    containers:
    - command:
      - sleep
      - "3600"
      image: confluentinc/cp-kafka:7.4.0
      imagePullPolicy: IfNotPresent
      name: kafka
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-b5tbf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-b5tbf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T17:57:39Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:57:49Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:57:49Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T17:57:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://bec76e3b51fa4ea8ae9634d34ffca6a5643fffb2b69c131d672b63106d89cf5f
      image: docker.io/confluentinc/cp-kafka:7.4.0
      imageID: docker.io/confluentinc/cp-kafka@sha256:187dac6627e7906c350f5f8c982f80ce735ff1a0e571a20de6000a309a12ce63
      lastState: {}
      name: kafka
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://bec76e3b51fa4ea8ae9634d34ffca6a5643fffb2b69c131d672b63106d89cf5f
          exitCode: 0
          finishedAt: "2025-08-13T18:57:49Z"
          reason: Completed
          startedAt: "2025-08-13T17:57:49Z"
    hostIP: 37.59.98.241
    phase: Succeeded
    podIP: 10.42.0.82
    podIPs:
    - ip: 10.42.0.82
    qosClass: BestEffort
    startTime: "2025-08-13T17:57:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"name":"kafka-admin","namespace":"kafka"},"spec":{"containers":[{"command":["sleep","3600"],"image":"confluentinc/cp-kafka:7.4.0","name":"kafka"}],"restartPolicy":"Never"}}
    creationTimestamp: "2025-08-13T18:05:48Z"
    name: kafka-admin
    namespace: kafka
    resourceVersion: "28421"
    uid: c04df92b-2238-4cfe-bd62-57b5d6e47174
  spec:
    containers:
    - command:
      - sleep
      - "3600"
      image: confluentinc/cp-kafka:7.4.0
      imagePullPolicy: IfNotPresent
      name: kafka
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-88f47
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-88f47
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:05:48Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T19:05:49Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T19:05:49Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-13T18:05:48Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fac0bbcab388e6c3f5589c4863957c3802e17436f4383fab817294d54e9b1a28
      image: docker.io/confluentinc/cp-kafka:7.4.0
      imageID: docker.io/confluentinc/cp-kafka@sha256:187dac6627e7906c350f5f8c982f80ce735ff1a0e571a20de6000a309a12ce63
      lastState: {}
      name: kafka
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://fac0bbcab388e6c3f5589c4863957c3802e17436f4383fab817294d54e9b1a28
          exitCode: 0
          finishedAt: "2025-08-13T19:05:48Z"
          reason: Completed
          startedAt: "2025-08-13T18:05:48Z"
    hostIP: 37.59.98.241
    phase: Succeeded
    podIP: 10.42.0.87
    podIPs:
    - ip: 10.42.0.87
    qosClass: BestEffort
    startTime: "2025-08-13T18:05:48Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-08-14T11:18:35Z"
      prometheus.io/path: /metrics
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-14T11:43:29Z"
    generateName: api-gateway-5699c86b74-
    labels:
      app: api-gateway
      pod-template-hash: 5699c86b74
      version: v1
    name: api-gateway-5699c86b74-89r6k
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: api-gateway-5699c86b74
      uid: fcf59757-b86c-4bb6-94d7-616148e8773c
    resourceVersion: "179900"
    uid: 3985a9a1-8cff-47e0-8091-e69c920c53d3
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - api-gateway
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: false
    containers:
    - args:
      - dist/main.js
      command:
      - node
      env:
      - name: RESEND_API_KEY
        valueFrom:
          secretKeyRef:
            key: resend-api-key
            name: resend-secret
      - name: EMAIL_FROM
        value: Travelyzer <onboarding@resend.dev>
      - name: PORT
        value: "8080"
      - name: ADMIN_PORT
        value: "8081"
      - name: NODE_ENV
        value: production
      - name: npm_config_cache
        value: /tmp/.npm
      - name: LOG_LEVEL
        value: info
      - name: KAFKA_BROKERS
        value: mercurious-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092
      - name: KAFKA_SECURITY_PROTOCOL
        value: SASL_PLAINTEXT
      - name: KAFKA_SASL_MECHANISM
        value: SCRAM-SHA-512
      - name: KAFKA_SASL_USERNAME
        valueFrom:
          secretKeyRef:
            key: username
            name: kafka-credentials
      - name: KAFKA_SASL_PASSWORD
        valueFrom:
          secretKeyRef:
            key: password
            name: kafka-credentials
      - name: MONGODB_URI
        valueFrom:
          secretKeyRef:
            key: mongodb-uri
            name: external-services
      - name: REDIS_URI
        valueFrom:
          secretKeyRef:
            key: redis-uri
            name: external-services
      - name: REDIS_URL
        valueFrom:
          configMapKeyRef:
            key: REDIS_URL
            name: microservices-config
      - name: REDIS_PASSWORD
        valueFrom:
          configMapKeyRef:
            key: REDIS_PASSWORD
            name: microservices-config
      - name: REDIS_USERNAME
        valueFrom:
          configMapKeyRef:
            key: REDIS_USERNAME
            name: microservices-config
      - name: MONGO_URI
        valueFrom:
          configMapKeyRef:
            key: MONGO_URI
            name: microservices-config
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            key: openai-api-key
            name: api-keys
      - name: GOOGLE_PLACES_API_KEY
        valueFrom:
          secretKeyRef:
            key: google-places-api-key
            name: api-keys
      - name: GOOGLE_CLIENT_ID
        valueFrom:
          secretKeyRef:
            key: google-client-id
            name: api-keys
      - name: GOOGLE_CLIENT_SECRET
        valueFrom:
          secretKeyRef:
            key: google-client-secret
            name: api-keys
      - name: OPENWEATHER_API_KEY
        valueFrom:
          secretKeyRef:
            key: openweather-api-key
            name: api-keys
      - name: BETTER_AUTH_SECRET
        valueFrom:
          secretKeyRef:
            key: better-auth-secret
            name: api-keys
      - name: CLIENT_DEV_URL
        valueFrom:
          configMapKeyRef:
            key: CLIENT_DEV_URL
            name: microservices-config
      - name: CLIENT_PLANNER_URL
        valueFrom:
          configMapKeyRef:
            key: CLIENT_PLANNER_URL
            name: microservices-config
      - name: CLIENT_FRONT_URL
        valueFrom:
          configMapKeyRef:
            key: CLIENT_FRONT_URL
            name: microservices-config
      image: ghcr.io/team-mercurious/api-gateway:latest
      imagePullPolicy: Always
      name: api-gateway
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8081
        name: admin
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 2Gi
        requests:
          cpu: 500m
          memory: 1Gi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: false
        runAsNonRoot: false
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/cache
        name: var-cache
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-pull-secret
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000
    serviceAccount: api-gateway
    serviceAccountName: api-gateway
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp
    - emptyDir: {}
      name: var-cache
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://65546a05d3cb770058b6abf4420b410088f854d5dcac1ae037f8da91adb9ecab
      image: ghcr.io/team-mercurious/api-gateway:latest
      imageID: ghcr.io/team-mercurious/api-gateway@sha256:6dc0f6c662e5afb6e91efcad1d962f704f0bd65f5304c46b77f42d1385eb61f1
      lastState: {}
      name: api-gateway
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-14T11:43:30Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.231
    podIPs:
    - ip: 10.42.0.231
    qosClass: Burstable
    startTime: "2025-08-14T11:43:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-08-14T11:18:35Z"
      prometheus.io/path: /metrics
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-14T11:43:29Z"
    generateName: api-generation-c5cf55cc6-
    labels:
      app: api-generation
      pod-template-hash: c5cf55cc6
      version: v1
    name: api-generation-c5cf55cc6-5mrmn
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: api-generation-c5cf55cc6
      uid: b15adc67-e59e-4e57-b5aa-732e29f9fa48
    resourceVersion: "179992"
    uid: e9be7d5d-14c9-40f2-81bf-b59595f789c0
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - api-generation
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: false
    containers:
    - env:
      - name: PORT
        value: "8080"
      - name: LOG_LEVEL
        value: info
      - name: KAFKA_BROKERS
        value: mercurious-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092
      - name: KAFKA_SECURITY_PROTOCOL
        value: SASL_PLAINTEXT
      - name: KAFKA_SASL_MECHANISM
        value: SCRAM-SHA-512
      - name: KAFKA_SASL_USERNAME
        valueFrom:
          secretKeyRef:
            key: username
            name: kafka-credentials
      - name: KAFKA_SASL_PASSWORD
        valueFrom:
          secretKeyRef:
            key: password
            name: kafka-credentials
      - name: MONGODB_URI
        valueFrom:
          secretKeyRef:
            key: mongodb-uri
            name: external-services
      - name: MONGO_URI
        valueFrom:
          configMapKeyRef:
            key: MONGO_URI
            name: microservices-config
      - name: MONGO_URL
        valueFrom:
          configMapKeyRef:
            key: MONGO_URL
            name: microservices-config
      - name: DATABASE_URL
        valueFrom:
          configMapKeyRef:
            key: DATABASE_URL
            name: microservices-config
      - name: REDIS_URI
        valueFrom:
          secretKeyRef:
            key: redis-uri
            name: external-services
      - name: REDIS_URL
        valueFrom:
          configMapKeyRef:
            key: REDIS_URL
            name: microservices-config
      - name: REDIS_HOST
        valueFrom:
          configMapKeyRef:
            key: REDIS_HOST
            name: microservices-config
      - name: REDIS_PORT
        valueFrom:
          configMapKeyRef:
            key: REDIS_PORT
            name: microservices-config
      - name: REDIS_USERNAME
        valueFrom:
          configMapKeyRef:
            key: REDIS_USERNAME
            name: microservices-config
      - name: REDIS_PASSWORD
        valueFrom:
          configMapKeyRef:
            key: REDIS_PASSWORD
            name: microservices-config
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            key: openai-api-key
            name: api-keys
      - name: GOOGLE_PLACES_API_KEY
        valueFrom:
          secretKeyRef:
            key: google-places-api-key
            name: api-keys
      - name: NODE_ENV
        valueFrom:
          configMapKeyRef:
            key: NODE_ENV
            name: microservices-config
      image: ghcr.io/team-mercurious/api-generation:latest
      imagePullPolicy: Always
      livenessProbe:
        exec:
          command:
          - sh
          - -c
          - ps aux | grep '[n]ode' || exit 1
        failureThreshold: 3
        initialDelaySeconds: 60
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 5
      name: api-generation
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - ps aux | grep '[n]ode' || exit 1
        failureThreshold: 3
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/cache
        name: var-cache
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-pull-secret
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000
    serviceAccount: api-generation
    serviceAccountName: api-generation
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp
    - emptyDir: {}
      name: var-cache
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:44:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:44:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7c902064a5443edf49f0495be9d7caf7f77ef4ae0bc26303bb86b377630996fd
      image: ghcr.io/team-mercurious/api-generation:latest
      imageID: ghcr.io/team-mercurious/api-generation@sha256:1ede3223c92e063c0ab92671ef39f1c7d18d9a656abc5236396245b84c5898c7
      lastState: {}
      name: api-generation
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-14T11:43:30Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.233
    podIPs:
    - ip: 10.42.0.233
    qosClass: Burstable
    startTime: "2025-08-14T11:43:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-08-14T11:18:35Z"
      prometheus.io/path: /metrics
      prometheus.io/port: "8080"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-08-14T11:43:29Z"
    generateName: api-enrichment-5d86768457-
    labels:
      app: api-enrichment
      pod-template-hash: 5d86768457
      version: v1
    name: api-enrichment-5d86768457-tgc25
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: api-enrichment-5d86768457
      uid: 90842e8d-5a69-4318-9ac5-367dce975aed
    resourceVersion: "179996"
    uid: 6ca51e50-b787-4ec7-a697-53569b66673c
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - api-enrichment
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: false
    containers:
    - env:
      - name: PORT
        value: "8080"
      - name: LOG_LEVEL
        value: info
      - name: KAFKA_BROKERS
        value: mercurious-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092
      - name: KAFKA_SECURITY_PROTOCOL
        value: SASL_PLAINTEXT
      - name: KAFKA_SASL_MECHANISM
        value: SCRAM-SHA-512
      - name: KAFKA_SASL_USERNAME
        valueFrom:
          secretKeyRef:
            key: username
            name: kafka-credentials
      - name: KAFKA_SASL_PASSWORD
        valueFrom:
          secretKeyRef:
            key: password
            name: kafka-credentials
      - name: MONGODB_URI
        valueFrom:
          secretKeyRef:
            key: mongodb-uri
            name: external-services
      - name: MONGO_URI
        valueFrom:
          configMapKeyRef:
            key: MONGO_URI
            name: microservices-config
      - name: MONGO_URL
        valueFrom:
          configMapKeyRef:
            key: MONGO_URL
            name: microservices-config
      - name: DATABASE_URL
        valueFrom:
          configMapKeyRef:
            key: DATABASE_URL
            name: microservices-config
      - name: REDIS_URI
        valueFrom:
          secretKeyRef:
            key: redis-uri
            name: external-services
      - name: REDIS_URL
        valueFrom:
          configMapKeyRef:
            key: REDIS_URL
            name: microservices-config
      - name: REDIS_HOST
        valueFrom:
          configMapKeyRef:
            key: REDIS_HOST
            name: microservices-config
      - name: REDIS_PORT
        valueFrom:
          configMapKeyRef:
            key: REDIS_PORT
            name: microservices-config
      - name: REDIS_USERNAME
        valueFrom:
          configMapKeyRef:
            key: REDIS_USERNAME
            name: microservices-config
      - name: REDIS_PASSWORD
        valueFrom:
          configMapKeyRef:
            key: REDIS_PASSWORD
            name: microservices-config
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            key: openai-api-key
            name: api-keys
      - name: NODE_ENV
        valueFrom:
          configMapKeyRef:
            key: NODE_ENV
            name: microservices-config
      image: ghcr.io/team-mercurious/api-enrichment:latest
      imagePullPolicy: Always
      livenessProbe:
        exec:
          command:
          - sh
          - -c
          - ps aux | grep '[n]ode' || exit 1
        failureThreshold: 3
        initialDelaySeconds: 60
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 5
      name: api-enrichment
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - ps aux | grep '[n]ode' || exit 1
        failureThreshold: 3
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/cache
        name: var-cache
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-pull-secret
    nodeName: vps-6227e9e1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000
    serviceAccount: api-enrichment
    serviceAccountName: api-enrichment
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp
    - emptyDir: {}
      name: var-cache
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:44:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:44:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-08-14T11:43:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://49ff3abce3a80415c86442cffb518600b3064be3cb99a69f1a0bdd4da31008d9
      image: ghcr.io/team-mercurious/api-enrichment:latest
      imageID: ghcr.io/team-mercurious/api-enrichment@sha256:d179fa2701df7bc013df25cf82fda667c496feb28247fe6dabc1f163c1c9d730
      lastState: {}
      name: api-enrichment
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-08-14T11:43:30Z"
    hostIP: 37.59.98.241
    phase: Running
    podIP: 10.42.0.232
    podIPs:
    - ip: 10.42.0.232
    qosClass: Burstable
    startTime: "2025-08-14T11:43:29Z"
kind: List
metadata:
  resourceVersion: ""
